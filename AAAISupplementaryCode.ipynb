{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u1kvRigs35VT",
        "QGXy_nJKp-p-",
        "d5Va7RznmrZc",
        "MtrGAGzR58ZI",
        "MQU2tvVR6CBv",
        "pNe7sNpD7GCz",
        "_wnkdiZJqre0",
        "P_0weiAHqu2b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MC-CP Supplementary Code"
      ],
      "metadata": {
        "id": "cHYPtNtY3tVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dear reviewer,\n",
        "In this notebook you can find all of the supplementary code behind our method, MC-CP. 🙂"
      ],
      "metadata": {
        "id": "jj-NeqR33wLY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misc (Imports, generic functions, etc.)"
      ],
      "metadata": {
        "id": "u1kvRigs35VT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section is full of various imports that are needed throughout our tests, as well as functions that are used in most test sections. Unique code/functions that are unique to a specific test can be found under that test.\n",
        "\n"
      ],
      "metadata": {
        "id": "c6nKuZ2H7P5q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7Mpqki7x3p69"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist, fashion_mnist, cifar10, cifar100, boston_housing\n",
        "from keras.models import Model\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import random\n",
        "from collections import Counter\n",
        "from keras import applications\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "from keras.utils import load_img\n",
        "from PIL import ImageOps\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar10():\n",
        "  (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "  x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
        "  y_train = keras.utils.to_categorical(y_train, 10)\n",
        "  y_test = keras.utils.to_categorical(y_test, 10)\n",
        "  input_shape = (32, 32, 3)\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "  return x_train, y_train, x_test, y_test, input_shape"
      ],
      "metadata": {
        "id": "8zjA0omV4AQZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar100():\n",
        "  (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode=\"fine\")\n",
        "  x_train = x_train.reshape(x_train.shape[0], 32, 32, 3)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 32, 32, 3)\n",
        "  y_train = keras.utils.to_categorical(y_train, 100)\n",
        "  y_test = keras.utils.to_categorical(y_test, 100)\n",
        "  input_shape = (32, 32, 3)\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "  return x_train, y_train, x_test, y_test, input_shape"
      ],
      "metadata": {
        "id": "p_hku6wn4BIV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_mnist():\n",
        "  (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "  y_train = keras.utils.to_categorical(y_train, 10)\n",
        "  y_test = keras.utils.to_categorical(y_test, 10)\n",
        "  input_shape = (28, 28, 1)\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "  return x_train, y_train, x_test, y_test, input_shape"
      ],
      "metadata": {
        "id": "bYTM0c6Q4B8a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_fashion_mnist():\n",
        "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "  y_train = keras.utils.to_categorical(y_train, 10)\n",
        "  y_test = keras.utils.to_categorical(y_test, 10)\n",
        "  input_shape = (28, 28, 1)\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "  return x_train, y_train, x_test, y_test, input_shape"
      ],
      "metadata": {
        "id": "g73smOVI4Csn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_tiny_imagenet():\n",
        "  dataset = load_dataset(\"zh-plus/tiny-imagenet\")\n",
        "  train = dataset['train']\n",
        "  x_train = [x['image'] for x in train]\n",
        "  x_train = [img_to_array(x) for x in x_train]\n",
        "  y_train = [x['label'] for x in train]\n",
        "  test = dataset['valid']\n",
        "  x_test = [x['image'] for x in test]\n",
        "  x_test = [img_to_array(x) for x in x_test]\n",
        "  y_test = [x['label'] for x in test]\n",
        "\n",
        "  culledx_train = [ind for ind, x in enumerate(x_train) if x.shape != (64, 64, 3)]\n",
        "  x_train = [x for x in x_train if x.shape == (64, 64, 3)]\n",
        "  for index in sorted(culledx_train, reverse=True):\n",
        "    del y_train[index]\n",
        "\n",
        "  culledx_test = [ind for ind, x in enumerate(x_test) if x.shape != (64, 64, 3)]\n",
        "  x_test = [x for x in x_test if x.shape == (64, 64, 3)]\n",
        "  for index in sorted(culledx_test, reverse=True):\n",
        "    del y_test[index]\n",
        "\n",
        "  x_train, x_test = np.asarray(x_train), np.asarray(x_test)\n",
        "  y_train, y_test = np.asarray(y_train), np.asarray(y_test)\n",
        "  x_train = x_train.reshape(x_train.shape[0], 64, 64, 3)\n",
        "  x_test = x_test.reshape(x_test.shape[0], 64, 64, 3)\n",
        "  y_train = keras.utils.to_categorical(y_train, 200)\n",
        "  y_test = keras.utils.to_categorical(y_test, 200)\n",
        "  input_shape = (64, 64, 3)\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "  x_train /= 255\n",
        "  x_test /= 255\n",
        "\n",
        "  return x_train, y_train, x_test, y_test, input_shape"
      ],
      "metadata": {
        "id": "9OLgs5EVgSEt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_housing_prices():\n",
        "  (x_train, y_train), (x_test, y_test) = boston_housing.load_data(path=\"boston_housing.npz\", test_split=0.2, seed=64)\n",
        "  input_shape = x_train.shape[1]\n",
        "  x_train = np.asarray(x_train)\n",
        "  y_train = np.asarray(y_train)\n",
        "  x_test = np.asarray(x_test)\n",
        "  y_test = np.asarray(y_test)\n",
        "  n_train = x_train.shape[0]\n",
        "  in_shape = x_train.shape[1]\n",
        "\n",
        "  idx = np.random.permutation(n_train)\n",
        "  n_half = int(np.floor(n_train/2))\n",
        "  idx_train, idx_cal = idx[:n_half], idx[n_half:2*n_half]\n",
        "\n",
        "  scalerX = StandardScaler()\n",
        "  scalerX = scalerX.fit(x_train[idx_train])\n",
        "\n",
        "  x_train = scalerX.transform(x_train)\n",
        "  x_test = scalerX.transform(x_test)\n",
        "\n",
        "  mean_y_train = np.mean(np.abs(y_train[idx_train]))\n",
        "  y_train = np.squeeze(y_train)/mean_y_train\n",
        "  y_test = np.squeeze(y_test)/mean_y_train\n",
        "\n",
        "  return x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape"
      ],
      "metadata": {
        "id": "J2ZLyjiM4Dl5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_blog_feedback():\n",
        "  dataset = load_dataset(\"wwydmanski/blog-feedback\")\n",
        "  train = pd.DataFrame(data=dataset['train'])\n",
        "  test = pd.DataFrame(data=dataset['test'])\n",
        "\n",
        "  y_train = train['target']\n",
        "  del train['target']\n",
        "  y_test = test['target']\n",
        "  del test['target']\n",
        "\n",
        "  x_train = np.asarray(train)\n",
        "  y_train = np.asarray(y_train)\n",
        "  x_test = np.asarray(test)\n",
        "  y_test = np.asarray(y_test)\n",
        "  input_shape = x_train.shape[1]\n",
        "\n",
        "  n_train = x_train.shape[0]\n",
        "  idx = np.random.permutation(n_train)\n",
        "  n_half = int(np.floor(n_train/2))\n",
        "  idx_train, idx_cal = idx[:n_half], idx[n_half:2*n_half]\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train[idx_train])\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "\n",
        "  mean_y_train = np.mean(np.abs(y_train[idx_train]))\n",
        "  y_train = np.squeeze(y_train)/mean_y_train\n",
        "  y_test = np.squeeze(y_test)/mean_y_train\n",
        "\n",
        "  return x_train, x_test, y_train, y_test, input_shape"
      ],
      "metadata": {
        "id": "z59_L9OVgTjG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_concrete():\n",
        "  column_names = [\"Cement\", \"Blast Furnace Slag\", \"Fly Ash\", \"Water\", \"Superplasticizer\", \"Coarse Aggregate\",\n",
        "                  \"Fine Aggregate\", \"Age\", \"Concrete compressive strength\"]\n",
        "  data = pd.read_csv('Concrete_Data.csv', names=column_names)\n",
        "  data.drop(index = data.index[0], axis=0, inplace=True)\n",
        "\n",
        "  y = data['Concrete compressive strength'].astype(float)\n",
        "  del data['Concrete compressive strength']\n",
        "  x = data.astype(float)\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "  x_train = np.asarray(x_train)\n",
        "  y_train = np.asarray(y_train)\n",
        "  x_test = np.asarray(x_test)\n",
        "  y_test = np.asarray(y_test)\n",
        "  input_shape = x_train.shape[1]\n",
        "\n",
        "  n_train = x_train.shape[0]\n",
        "  idx = np.random.permutation(n_train)\n",
        "  n_half = int(np.floor(n_train/2))\n",
        "  idx_train, idx_cal = idx[:n_half], idx[n_half:2*n_half]\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train[idx_train])\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "\n",
        "  mean_y_train = np.mean(np.abs(y_train[idx_train]))\n",
        "  y_train = np.squeeze(y_train)/mean_y_train\n",
        "  y_test = np.squeeze(y_test)/mean_y_train\n",
        "\n",
        "  return x_train, x_test, y_train, y_test, input_shape"
      ],
      "metadata": {
        "id": "MJYQrK0sgU5W"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_abalone():\n",
        "  # load data\n",
        "  column_names = [\"sex\", \"length\", \"diameter\", \"height\", \"whole weight\",\n",
        "                \"shucked weight\", \"viscera weight\", \"shell weight\", \"rings\"]\n",
        "  data = pd.read_csv('abalone.data.csv', names=column_names)\n",
        "\n",
        "  # change string to boolean\n",
        "  for label in \"MFI\":\n",
        "    data[label] = data[\"sex\"] == label\n",
        "  del data[\"sex\"]\n",
        "\n",
        "  y = data.rings.values.astype(float)\n",
        "  del data['rings']\n",
        "  x = data.values.astype(float)\n",
        "\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "  x_train = np.asarray(x_train)\n",
        "  y_train = np.asarray(y_train)\n",
        "  x_test = np.asarray(x_test)\n",
        "  y_test = np.asarray(y_test)\n",
        "  input_shape = x_train.shape[1]\n",
        "\n",
        "\n",
        "  n_train = x_train.shape[0]\n",
        "  idx = np.random.permutation(n_train)\n",
        "  n_half = int(np.floor(n_train/2))\n",
        "  idx_train, idx_cal = idx[:n_half], idx[n_half:2*n_half]\n",
        "\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(x_train[idx_train])\n",
        "\n",
        "  x_train = scaler.transform(x_train)\n",
        "  x_test = scaler.transform(x_test)\n",
        "\n",
        "  mean_y_train = np.mean(np.abs(y_train[idx_train]))\n",
        "  y_train = np.squeeze(y_train)/mean_y_train\n",
        "  y_test = np.squeeze(y_test)/mean_y_train\n",
        "\n",
        "  return x_train, x_test, y_train, y_test, input_shape"
      ],
      "metadata": {
        "id": "3CTXuJI-gZeP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dropout_layer(input, percent, montecarlo):\n",
        "  if montecarlo:\n",
        "    return keras.layers.Dropout(percent)(input, training=True)\n",
        "  else:\n",
        "    return keras.layers.Dropout(percent)(input)\n",
        "\n",
        "def cnn_model(montecarlo, activation, input_shape, output_dims):\n",
        "  input_layer = keras.layers.Input(input_shape)\n",
        "  layer1A = keras.layers.Conv2D(32, (3, 3), activation=activation)(input_layer)\n",
        "  pooling1 = keras.layers.MaxPooling2D((2, 2))(layer1A)\n",
        "  dropout1 = dropout_layer(pooling1, 0.5, montecarlo)\n",
        "\n",
        "  layer1B = keras.layers.Conv2D(64, (3, 3), activation=activation)(dropout1)\n",
        "  pooling2 = keras.layers.MaxPooling2D((2, 2))(layer1B)\n",
        "  dropout2 = dropout_layer(pooling2, 0.5, montecarlo)\n",
        "\n",
        "  flatten_layer = keras.layers.Flatten()(dropout2)\n",
        "  dense1 = keras.layers.Dense(128, activation=activation)(flatten_layer)\n",
        "  output_layer = keras.layers.Dense(output_dims, activation='softmax')(dense1)\n",
        "\n",
        "  model = Model(inputs=input_layer, outputs=output_layer)\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                optimizer=keras.optimizers.SGD(learning_rate=0.01, momentum=0.9),\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "mPu9Rz464FvP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Our dynamic MC method\n",
        "Params:\n",
        "  x_test -> a testing dataset to produce predictions on\n",
        "  model -> a model to predict with\n",
        "  patience -> how many forward passes to wait when all classes are lower than\n",
        "  the min_delta threshold\n",
        "  min_delta -> the threshold a class how to be lower than to be considered stable\n",
        "  max_mc -> the maximum number of forward passes if the classes never converge\n",
        "\n",
        "Returns:\n",
        "  A set of predictions\n",
        "\"\"\"\n",
        "def dynamic_mc_predict(x_test, model, patience, min_delta, max_mc):\n",
        "  montecarlo_predictions = []\n",
        "  var_diffs = []\n",
        "  for data in tqdm.tqdm(x_test):\n",
        "    current_patience_count = 0\n",
        "    prev_variance = []\n",
        "    predictions = []\n",
        "    while True:\n",
        "      prediction = model.predict(np.expand_dims(data, axis=0), verbose=0)\n",
        "      predictions.append(prediction)\n",
        "      variance = np.array(predictions).std(axis=0)\n",
        "      if len(predictions) != 1:\n",
        "        var_diff = abs(np.subtract(prev_variance, variance))\n",
        "        var_diffs.append(var_diff)\n",
        "        if np.all(var_diff <= min_delta) == True:\n",
        "          current_patience_count +=1\n",
        "        else:\n",
        "          current_patience_count = 0\n",
        "      if current_patience_count > patience or len(predictions) == max_mc:\n",
        "        break\n",
        "      prev_variance = variance\n",
        "    montecarlo_predictions.append(np.array(predictions).mean(axis=0))\n",
        "  return montecarlo_predictions"
      ],
      "metadata": {
        "id": "3OXkVdhe4LUc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Only difference here is we format the predictions into the final array to work nicely with a quantile regressor\n",
        "\"\"\"\n",
        "def dynamic_mc_predict_reg(x_test, model, patience, min_delta, max_mc):\n",
        "  montecarlo_predictions = []\n",
        "  var_diffs = []\n",
        "  for data in tqdm.tqdm(x_test):\n",
        "    current_patience_count = 0\n",
        "    prev_variance = []\n",
        "    predictions = []\n",
        "    while True:\n",
        "      prediction = model.predict(np.expand_dims(data, axis=0), verbose=0)\n",
        "      predictions.append(prediction)\n",
        "      variance = np.array(predictions).std(axis=0)\n",
        "      if len(predictions) != 1:\n",
        "        var_diff = abs(np.subtract(prev_variance, variance))\n",
        "        var_diffs.append(var_diff)\n",
        "        if np.all(var_diff <= min_delta) == True:\n",
        "          current_patience_count +=1\n",
        "        else:\n",
        "          current_patience_count = 0\n",
        "      if current_patience_count > patience or len(predictions) == max_mc:\n",
        "        break\n",
        "      prev_variance = variance\n",
        "    predictions = np.asarray(predictions).mean(axis=0)\n",
        "    predictions = np.reshape(predictions, predictions.shape[0:2])\n",
        "    montecarlo_predictions.append(predictions)\n",
        "  montecarlo_predictions = np.asarray(montecarlo_predictions)\n",
        "  return montecarlo_predictions"
      ],
      "metadata": {
        "id": "LQrxla9Gry7N"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Dynamic MC Once"
      ],
      "metadata": {
        "id": "QGXy_nJKp-p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dynamic_mc(x_train, y_train, x_test, y_test, output_dims):\n",
        "  model = cnn_model(montecarlo=True, activation='relu', input_shape=input_shape, output_dims=output_dims)\n",
        "  history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n",
        "\n",
        "  # dynamic mc\n",
        "  patience = 10\n",
        "  min_delta = 5e-4\n",
        "  max_mc = 1000\n",
        "  montecarlo_predictions = []\n",
        "  var_diffs = []\n",
        "  for image in tqdm.tqdm(x_test):\n",
        "    current_patience_count = 0\n",
        "    prev_variance = []\n",
        "    predictions = []\n",
        "    while True:\n",
        "      prediction = model.predict(np.expand_dims(image, axis=0), verbose=0)\n",
        "      predictions.append(prediction)\n",
        "      variance = np.array(predictions).std(axis=0)\n",
        "      if len(predictions) != 1:\n",
        "        var_diff = abs(np.subtract(prev_variance, variance))\n",
        "        var_diffs.append(var_diff)\n",
        "        if np.all(var_diff <= min_delta) == True:\n",
        "          current_patience_count +=1\n",
        "        else:\n",
        "          current_patience_count = 0\n",
        "      if current_patience_count > patience or len(predictions) == max_mc:\n",
        "        break\n",
        "      prev_variance = variance\n",
        "    montecarlo_predictions.append(np.array(predictions).mean(axis=0))\n",
        "  return var_diffs"
      ],
      "metadata": {
        "id": "js2RA6y5qXgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n",
        "# convert to readable class names\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "y_test_new = np.array([np.argmax(y, axis=None, out=None) for y in y_test])\n",
        "\n",
        "# show example image and its corresponding label\n",
        "plt.imshow(x_test[1])\n",
        "true_label = int(y_test_new[1])\n",
        "print(class_names[true_label])"
      ],
      "metadata": {
        "id": "wp5BfS1Bj4-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_diff = dynamic_mc(x_train, y_train, x_test[1:2], y_test[1:2], output_dims=10)"
      ],
      "metadata": {
        "id": "lxILQ942qC39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class0_diff = [x[0][0] for x in var_diff]\n",
        "class1_diff = [x[0][1] for x in var_diff]\n",
        "class2_diff = [x[0][2] for x in var_diff]\n",
        "class3_diff = [x[0][3] for x in var_diff]\n",
        "class4_diff = [x[0][4] for x in var_diff]\n",
        "class5_diff = [x[0][5] for x in var_diff]\n",
        "class6_diff = [x[0][6] for x in var_diff]\n",
        "class7_diff = [x[0][7] for x in var_diff]\n",
        "class8_diff = [x[0][8] for x in var_diff]\n",
        "class9_diff = [x[0][9] for x in var_diff]"
      ],
      "metadata": {
        "id": "dUx1PJZ_qdJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(0, len(var_diff)))\n",
        "plt.plot(x, class0_diff, label='Airplane')\n",
        "plt.plot(x, class1_diff, label='Automobile')\n",
        "plt.plot(x, class2_diff, label='Bird')\n",
        "plt.plot(x, class3_diff, label='Cat')\n",
        "plt.plot(x, class4_diff, label='Deer')\n",
        "plt.plot(x, class5_diff, label='Dog')\n",
        "plt.plot(x, class6_diff, label='Frog')\n",
        "plt.plot(x, class7_diff, label='Horse')\n",
        "plt.plot(x, class8_diff, label='Ship')\n",
        "plt.plot(x, class9_diff, label='Truck')\n",
        "\n",
        "plt.axhline(y=5e-4, color='r', label=\"Delta\", linestyle='--')\n",
        "plt.ylabel(\"Difference in Variance\")\n",
        "plt.xlabel(\"Ensemble No.\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "xFTRT2_kqd1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Dynamic MC Once for Regression"
      ],
      "metadata": {
        "id": "d5Va7RznmrZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiQuantileLoss(tf.keras.losses.Loss):\n",
        "\n",
        "    def __init__(self, quantiles:list, **kwargs):\n",
        "        super(MultiQuantileLoss, self).__init__(**kwargs)\n",
        "\n",
        "        self.quantiles = quantiles\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "\n",
        "        # get quantile value\n",
        "        q_id = int(y_pred.name.split(\"/\")[1][1:])\n",
        "        q = self.quantiles[q_id]\n",
        "\n",
        "        # minimize quantile error\n",
        "        q_error = tf.subtract(y_true, y_pred)\n",
        "        q_loss = tf.reduce_mean(tf.maximum(q*q_error, (q-1)*q_error), axis=-1)\n",
        "        return q_loss\n",
        "\n",
        "def build_mqnn(quantiles:list, training_x_values:np.ndarray, internal_nodes:list = [32, 32], montecarlo=False,\n",
        "               model_name:str = \"mqnn\", optimizer=None, input_normalization:bool = True):\n",
        "    input_dim = training_x_values.shape[1]\n",
        "    output_dim = len(quantiles)\n",
        "\n",
        "    # define normalizer\n",
        "    normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
        "    normalizer.adapt(training_x_values)\n",
        "\n",
        "    # build model's node structure\n",
        "    inputs = keras.layers.Input(shape=input_dim)\n",
        "    mdl = normalizer(inputs)\n",
        "    for n_nodes in internal_nodes:\n",
        "        mdl = keras.layers.Dense(n_nodes, activation='relu')(mdl)\n",
        "        mdl = keras.layers.Dropout(0.25)(mdl, training=montecarlo)\n",
        "    outputs = [keras.layers.Dense(1, activation='linear', name=\"q%d\" % q_i)(mdl) for q_i in range(output_dim)]\n",
        "    del input_dim, output_dim, mdl, normalizer\n",
        "\n",
        "    # define optimizer and loss functions\n",
        "    optm_func = tf.optimizers.Adam(learning_rate=0.001) if optimizer is None else optimizer\n",
        "    loss_func = MultiQuantileLoss(quantiles=quantiles)\n",
        "\n",
        "    # build and compile model\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
        "    model.compile(optimizer=optm_func, loss=loss_func, metrics=['mae'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "ozLwitdOm3n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dynamic_mc(x_train, y_train, x_test, y_test):\n",
        "  quantiles = [0.05, 0.95]\n",
        "  model = build_mqnn(quantiles, x_train, [128, 128], montecarlo=True)\n",
        "  history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "  # dynamic mc\n",
        "  patience = 10\n",
        "  min_delta = 5e-4\n",
        "  max_mc = 1000\n",
        "  montecarlo_predictions = []\n",
        "  var_diffs = []\n",
        "  for dp in tqdm.tqdm(x_test):\n",
        "    current_patience_count = 0\n",
        "    prev_variance = []\n",
        "    predictions = []\n",
        "    while True:\n",
        "      prediction = model.predict(dp, verbose=0)\n",
        "      predictions.append(prediction)\n",
        "      variance = np.array(predictions).std(axis=0)\n",
        "      if len(predictions) != 1:\n",
        "        var_diff = abs(np.subtract(prev_variance, variance))\n",
        "        var_diffs.append(var_diff)\n",
        "        if np.all(var_diff <= min_delta) == True:\n",
        "          current_patience_count +=1\n",
        "        else:\n",
        "          current_patience_count = 0\n",
        "      if current_patience_count > patience or len(predictions) == max_mc:\n",
        "        break\n",
        "      prev_variance = variance\n",
        "    montecarlo_predictions.append(np.array(predictions).mean(axis=0))\n",
        "  return var_diffs"
      ],
      "metadata": {
        "id": "-EQdGfHQm8QJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n",
        "\n",
        "# show example dp and its corresponding true value\n",
        "print(x_test[0])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "id": "SXc5I2QfnPDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "var_diff = dynamic_mc(x_train, y_train, x_test[:1], y_test[:1])"
      ],
      "metadata": {
        "id": "vW38fUA-nfBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantup_diff = [x[0][0][0] for x in var_diff]\n",
        "quantlow_diff = [x[1][0][0] for x in var_diff]"
      ],
      "metadata": {
        "id": "uxpHz75ynrmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = list(range(0, len(var_diff)))\n",
        "plt.plot(x, quantup_diff, label='95%')\n",
        "plt.plot(x, quantlow_diff, label='5%')\n",
        "\n",
        "\n",
        "plt.axhline(y=5e-4, color='r', label=\"Delta\", linestyle='--')\n",
        "plt.ylabel(\"Difference in Variance\")\n",
        "plt.xlabel(\"Ensemble No.\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "gMQ8-GuwoYOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Produce test errors"
      ],
      "metadata": {
        "id": "MtrGAGzR58ZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section reproduces the table that showcases the test errors for each method on each dataset"
      ],
      "metadata": {
        "id": "v2RV0UfV7gzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "MQU2tvVR6CBv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are a set of unique functions that are only needed in the test section."
      ],
      "metadata": {
        "id": "4XMtDOKK7muZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_error_baseline(iterations, x_train, y_train, x_test, y_test, output_dims):\n",
        "  test_errors = []\n",
        "  for n in range(iterations):\n",
        "    model = cnn_model(montecarlo=False, activation='relu', input_shape=input_shape, output_dims=output_dims)\n",
        "    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    test_accuracy = score[1]\n",
        "    test_error = 1 - test_accuracy\n",
        "    test_errors.append(test_error)\n",
        "  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n",
        "  return test_errors"
      ],
      "metadata": {
        "id": "eYhATBOq6E_e"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_error_mc(iterations, x_train, y_train, x_test, y_test, output_dims):\n",
        "  test_errors = []\n",
        "  for n in range(iterations):\n",
        "    model = cnn_model(montecarlo=True, activation='relu', input_shape=input_shape, output_dims=output_dims)\n",
        "    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n",
        "    montecarlo_predictions = []\n",
        "    for i in tqdm.tqdm(range(1000)):\n",
        "      prediction = model.predict(x_test, batch_size=1000, verbose=0)\n",
        "      montecarlo_predictions.append(prediction)\n",
        "\n",
        "    # predictions\n",
        "    acc = 0\n",
        "    for idx in tqdm.tqdm(range(len(x_test))):\n",
        "      softmaxes = np.array([p[idx] for p in montecarlo_predictions])\n",
        "      prediction = softmaxes.mean(axis=0).argmax()\n",
        "      true_label = np.where(y_test[idx])[0]\n",
        "\n",
        "      if prediction == true_label:\n",
        "        acc += 1\n",
        "\n",
        "    test_accuracy = acc / len(x_test)\n",
        "    test_error = 1 - test_accuracy\n",
        "    test_errors.append(test_error)\n",
        "  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n",
        "  return test_errors"
      ],
      "metadata": {
        "id": "Llly2Sr76QGk"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_error_naive(iterations, x_train, y_train, x_test, y_test, output_dims):\n",
        "  test_errors = []\n",
        "  for n in range(iterations):\n",
        "    model = cnn_model(montecarlo=False, activation='relu', input_shape=input_shape, output_dims=output_dims)\n",
        "    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n",
        "    predictions = model.predict(x_test, batch_size=1000)\n",
        "\n",
        "    # calibration\n",
        "    n = 2500\n",
        "    alpha = 0.05\n",
        "    y_test_new = np.array([np.argmax(y, axis=None, out=None) for y in y_test])\n",
        "\n",
        "    idx = np.array([1] * n + [0] * (predictions.shape[0] - n)) > 0\n",
        "    np.random.shuffle(idx)\n",
        "    cal_softmax, val_softmax = predictions[idx, :], predictions[~idx, :]\n",
        "    cal_labels, val_labels = y_test_new[idx], y_test_new[~idx]\n",
        "\n",
        "    cal_scores = 1 - cal_softmax[np.arange(n), cal_labels]\n",
        "\n",
        "    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
        "    q_hat = np.quantile(cal_scores, q_level, method=\"higher\")\n",
        "    pred_sets = val_softmax >= (1 - q_hat)\n",
        "\n",
        "    # predictions\n",
        "    acc = 0\n",
        "    for idx in range(len(val_softmax)):\n",
        "      softmax = val_softmax[idx]\n",
        "      preds = softmax > 1 - q_hat\n",
        "      label_set = np.where(preds)[0]\n",
        "      true_label = np.where(val_labels[idx])[0]\n",
        "\n",
        "      if true_label in label_set:\n",
        "        acc += 1\n",
        "\n",
        "    test_accuracy = acc / len(x_test)\n",
        "    test_error = 1 - test_accuracy\n",
        "    test_errors.append(test_error)\n",
        "  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n",
        "  return test_errors"
      ],
      "metadata": {
        "id": "1_dIY00_6Skh"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_error_raps(iterations, x_train, y_train, x_test, y_test, output_dims):\n",
        "  test_errors = []\n",
        "  for n in range(iterations):\n",
        "    model = cnn_model(montecarlo=False, activation='relu', input_shape=input_shape, output_dims=output_dims)\n",
        "    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n",
        "    predictions = model.predict(x_test, batch_size=1000)\n",
        "\n",
        "    # calibration\n",
        "    n = 2500\n",
        "    alpha = 0.05\n",
        "    y_test_new = np.array([np.argmax(y, axis=None, out=None) for y in y_test])\n",
        "    lam_reg = 0.01\n",
        "    k_reg = 5\n",
        "    disallow_zero_sets = False\n",
        "    rand = False\n",
        "    reg_vec = np.array(k_reg * [0,] + (predictions.shape[1] - k_reg) * [lam_reg,])[None,:]\n",
        "\n",
        "    idx = np.array([1] * n + [0] * (predictions.shape[0] - n)) > 0\n",
        "    np.random.shuffle(idx)\n",
        "    cal_softmax, val_softmax = predictions[idx, :], predictions[~idx, :]\n",
        "    cal_labels, val_labels = y_test_new[idx], y_test_new[~idx]\n",
        "\n",
        "    cal_pi = cal_softmax.argsort(1)[:,::-1]\n",
        "    cal_srt = np.take_along_axis(cal_softmax, cal_pi, axis=1)\n",
        "    cal_srt_reg = cal_srt + reg_vec\n",
        "    cal_L = np.where(cal_pi == cal_labels[:, None])[1]\n",
        "    cal_scores = cal_srt_reg.cumsum(axis=1)[np.arange(n), cal_L] - np.random.rand(n) * cal_srt_reg[np.arange(n), cal_L]\n",
        "\n",
        "    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
        "    q_hat = np.quantile(cal_scores, q_level, method=\"higher\")\n",
        "\n",
        "    # predictions\n",
        "    acc = 0\n",
        "    for idx in range(len(val_softmax)):\n",
        "      softmax = val_softmax[idx]\n",
        "      _pi = np.argsort(softmax)[::-1]\n",
        "      _srt = np.take_along_axis(softmax, _pi, axis=0)\n",
        "      _srt_reg = _srt + reg_vec.squeeze()\n",
        "      _srt_reg_cumsum = _srt_reg.cumsum()\n",
        "      _ind = (_srt_reg_cumsum - np.random.rand() * _srt_reg) <= q_hat if rand else _srt_reg_cumsum - _srt_reg <= q_hat\n",
        "      if disallow_zero_sets: _ind[0] = True\n",
        "      pred_set = np.take_along_axis(_ind, _pi.argsort(), axis=0)\n",
        "      label_set = np.where(pred_set)[0]\n",
        "      true_label = np.where(val_labels[idx])[0]\n",
        "\n",
        "      if true_label in label_set:\n",
        "        acc += 1\n",
        "\n",
        "    test_accuracy = acc / len(x_test)\n",
        "    test_error = 1 - test_accuracy\n",
        "    test_errors.append(test_error)\n",
        "  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n",
        "  return test_errors"
      ],
      "metadata": {
        "id": "vvvU2PYD6T0A"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_error_mcraps(iterations, x_train, y_train, x_test, y_test, output_dims):\n",
        "  test_errors = []\n",
        "  for n in range(iterations):\n",
        "    model = cnn_model(montecarlo=True, activation='relu', input_shape=input_shape, output_dims=output_dims)\n",
        "    history = model.fit(x_train, y_train, batch_size=128, epochs=10, verbose=1)\n",
        "\n",
        "    montecarlo_predictions = dynamic_mc_predict(x_test, model, 10, 5e-4, 1000)\n",
        "\n",
        "    predictions = np.mean(montecarlo_predictions, axis=0)\n",
        "    # calibration\n",
        "    n = 2500\n",
        "    alpha = 0.05\n",
        "    y_test_new = np.array([np.argmax(y, axis=None, out=None) for y in y_test])\n",
        "    lam_reg = 0.01\n",
        "    k_reg = 5\n",
        "    disallow_zero_sets = False\n",
        "    rand = False\n",
        "    reg_vec = np.array(k_reg * [0,] + (predictions.shape[1] - k_reg) * [lam_reg,])[None,:]\n",
        "\n",
        "    idx = np.array([1] * n + [0] * (predictions.shape[0] - n)) > 0\n",
        "    np.random.shuffle(idx)\n",
        "    cal_softmax, val_softmax = predictions[idx, :], predictions[~idx, :]\n",
        "    cal_labels, val_labels = y_test_new[idx], y_test_new[~idx]\n",
        "\n",
        "    cal_pi = cal_softmax.argsort(1)[:,::-1]\n",
        "    cal_srt = np.take_along_axis(cal_softmax, cal_pi, axis=1)\n",
        "    cal_srt_reg = cal_srt + reg_vec\n",
        "    cal_L = np.where(cal_pi == cal_labels[:, None])[1]\n",
        "    cal_scores = cal_srt_reg.cumsum(axis=1)[np.arange(n), cal_L] - np.random.rand(n) * cal_srt_reg[np.arange(n), cal_L]\n",
        "\n",
        "    q_level = np.ceil((n + 1) * (1 - alpha)) / n\n",
        "    q_hat = np.quantile(cal_scores, q_level, method=\"higher\")\n",
        "\n",
        "    # predictions\n",
        "    acc = 0\n",
        "    for idx in range(len(val_softmax)):\n",
        "      _softmax = softmax = val_softmax[idx]\n",
        "      _softmax = softmaxes[0]\n",
        "      _pi = np.argsort(_softmax)[::-1]\n",
        "      _srt = np.take_along_axis(_softmax, _pi, axis=0)\n",
        "      _srt_reg = _srt + reg_vec.squeeze()\n",
        "      _srt_reg_cumsum = _srt_reg.cumsum()\n",
        "      _ind = (_srt_reg_cumsum - np.random.rand() * _srt_reg) <= q_hat if rand else _srt_reg_cumsum - _srt_reg <= q_hat\n",
        "      if disallow_zero_sets: _ind[0] = True\n",
        "      pred_set = np.take_along_axis(_ind, _pi.argsort(), axis=0)\n",
        "      label_set = np.where(pred_set)[0]\n",
        "      true_label = np.where(val_labels[idx])[0]\n",
        "\n",
        "      if true_label in label_set:\n",
        "        acc += 1\n",
        "\n",
        "    test_accuracy = acc / len(x_test)\n",
        "    test_error = 1 - test_accuracy\n",
        "    test_errors.append(test_error)\n",
        "  print(\"Test error: {:2f}, +/-{:2f}\".format(np.mean(test_errors), np.std(test_errors)))\n",
        "  return test_errors"
      ],
      "metadata": {
        "id": "lM0iJQTu6UxK"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tests"
      ],
      "metadata": {
        "id": "H4ooBX1j6Dg0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the test outputs for each dataset, as well as some plots when needed."
      ],
      "metadata": {
        "id": "2lw7WMF47rbs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CIFAR-10"
      ],
      "metadata": {
        "id": "N1j59z3u634b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n",
        "reg_test_error = test_error_baseline(5, x_train, y_train, x_test, y_test, output_dims=10)"
      ],
      "metadata": {
        "id": "usBpvts85_EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n",
        "mc_test_error = test_error_mc(5, x_train, y_train, x_test, y_test, output_dims=10)"
      ],
      "metadata": {
        "id": "AsfXIBlg69jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n",
        "naive_test_error = test_error_naive(5, x_train, y_train, x_test, y_test, output_dims=10)"
      ],
      "metadata": {
        "id": "G-yDBnSi7AUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n",
        "raps_test_error = test_error_raps(5, x_train, y_train, x_test, y_test, output_dims=10)"
      ],
      "metadata": {
        "id": "IYSahd-Q7Bgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, input_shape = load_cifar10()\n",
        "mcraps_test_error = test_error_mcraps(1, x_train, y_train, x_test, y_test, output_dims=10)"
      ],
      "metadata": {
        "id": "DEHZdVeq7CqZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "outputId": "099ad75b-0a24-4172-b36c-3a57b987cc22"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 25s 64ms/step - loss: 1.9876 - accuracy: 0.2575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|▏                                                                            | 31/10000 [00:14<1:16:05,  2.18it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m x_train, y_train, x_test, y_test, input_shape \u001b[38;5;241m=\u001b[39m load_cifar10()\n\u001b[1;32m----> 2\u001b[0m mcraps_test_error \u001b[38;5;241m=\u001b[39m \u001b[43mtest_error_mcraps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[72], line 7\u001b[0m, in \u001b[0;36mtest_error_mcraps\u001b[1;34m(iterations, x_train, y_train, x_test, y_test, output_dims)\u001b[0m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m cnn_model(montecarlo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39minput_shape, output_dims\u001b[38;5;241m=\u001b[39moutput_dims)\n\u001b[0;32m      5\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m montecarlo_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mdynamic_mc_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(montecarlo_predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# calibration\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[12], line 22\u001b[0m, in \u001b[0;36mdynamic_mc_predict\u001b[1;34m(x_test, model, patience, min_delta, max_mc)\u001b[0m\n\u001b[0;32m     20\u001b[0m predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m   prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m   predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[0;32m     24\u001b[0m   variance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(predictions)\u001b[38;5;241m.\u001b[39mstd(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CIFAR-10 Boxplot\n"
      ],
      "metadata": {
        "id": "pNe7sNpD7GCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = [i * 100 for i in reg_test_error]\n",
        "a2 = [i * 100 for i in mc_test_error]\n",
        "a3 = [i * 100 for i in naive_test_error]\n",
        "a4 = [i * 100 for i in raps_test_error]\n",
        "a5 = [i * 100 for i in mcraps_test_error]\n",
        "data = [a3, a4, a5]\n",
        "\n",
        "labels = ['Naive', 'RAPS', 'MC-CP']\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "bp = ax.boxplot(data, labels=labels, patch_artist = True,\n",
        "                medianprops = dict(color = \"black\"), vert=False)\n",
        "\n",
        "bp['boxes'][0].set_facecolor('salmon')\n",
        "bp['boxes'][1].set_facecolor('gold')\n",
        "bp['boxes'][2].set_facecolor('limegreen')\n",
        "\n",
        "ax.set_xlabel(\"Test Error %\")\n",
        "ax.set_title(\"CIFAR10 Mean Test Error\")"
      ],
      "metadata": {
        "id": "V_t00dR57H_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = [i * 100 for i in reg_test_error]\n",
        "a2 = [i * 100 for i in mc_test_error]\n",
        "a3 = [i * 100 for i in naive_test_error]\n",
        "a4 = [i * 100 for i in raps_test_error]\n",
        "a5 = [i * 100 for i in mcraps_test_error]\n",
        "data = [a1, a2, a3, a4, a5]\n",
        "\n",
        "labels = ['Baseline', 'MC', 'Naive', 'RAPS', 'MC-CP']\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.boxplot(data, labels=labels, vert=False)\n",
        "ax.set_ylabel(\"Test Error %\")\n",
        "ax.set_title(\"CIFAR10 Mean Test Error\")"
      ],
      "metadata": {
        "id": "PG5eauia7L2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deep Quantile Regressor"
      ],
      "metadata": {
        "id": "_wnkdiZJqre0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are the various functions and tests for the regression section of our paper."
      ],
      "metadata": {
        "id": "6maIYaKCtF1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions"
      ],
      "metadata": {
        "id": "P_0weiAHqu2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiQuantileLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, quantiles:list, **kwargs):\n",
        "        super(MultiQuantileLoss, self).__init__(**kwargs)\n",
        "\n",
        "        self.quantiles = quantiles\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "\n",
        "        # get quantile value\n",
        "        q_id = int(y_pred.name.split(\"/\")[1][1:])\n",
        "        q = self.quantiles[q_id]\n",
        "\n",
        "        # minimize quantile error\n",
        "        q_error = tf.subtract(y_true, y_pred)\n",
        "        q_loss = tf.reduce_mean(tf.maximum(q*q_error, (q-1)*q_error), axis=-1)\n",
        "        return q_loss"
      ],
      "metadata": {
        "id": "80ddqnT-q22g"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_mqnn(quantiles:list, training_x_values:np.ndarray, internal_nodes:list = [32, 32], montecarlo=False,\n",
        "               model_name:str = \"mqnn\", optimizer=None, input_normalization:bool = True):\n",
        "\n",
        "    input_dim = training_x_values.shape[1]\n",
        "    output_dim = len(quantiles)\n",
        "\n",
        "    # define normalizer\n",
        "    normalizer = tf.keras.layers.experimental.preprocessing.Normalization()\n",
        "    normalizer.adapt(training_x_values)\n",
        "\n",
        "    # build model's node structure\n",
        "    inputs = keras.layers.Input(shape=input_dim)\n",
        "    mdl = normalizer(inputs)\n",
        "    for i, n_nodes in enumerate(internal_nodes):\n",
        "        mdl = keras.layers.Dense(n_nodes, activation='relu')(mdl)\n",
        "        if i != (len(internal_nodes) - 1):\n",
        "          mdl = keras.layers.Dropout(0.1)(mdl, training=montecarlo)\n",
        "    outputs = [keras.layers.Dense(1, activation='linear', name=\"q%d\" % q_i)(mdl) for q_i in range(output_dim)]\n",
        "    del input_dim, output_dim, mdl, normalizer\n",
        "\n",
        "    # define optimizer and loss functions\n",
        "    optm_func = tf.optimizers.Adam(learning_rate=0.001) if optimizer is None else optimizer\n",
        "    loss_func = MultiQuantileLoss(quantiles=quantiles)\n",
        "\n",
        "    # build and compile model\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs, name=model_name)\n",
        "    model.compile(optimizer=optm_func, loss=loss_func, metrics=['mae'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "YO6XX1A0quRx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_test_mae_regular(iterations, x_train, y_train, x_test, y_test):\n",
        "  test_maes = []\n",
        "  quantiles = [0.05, 0.95]\n",
        "  for n in range(iterations):\n",
        "    model = build_mqnn(quantiles, x_train, [128, 128], False)\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
        "    prediction = model.predict(x_test, batch_size=1000, verbose=0)\n",
        "\n",
        "    upper_preds = []\n",
        "    lower_preds = []\n",
        "    # predictions\n",
        "    for idx in tqdm.tqdm(range(len(x_test))):\n",
        "      upper_pred = prediction[1][idx]\n",
        "      lower_pred = prediction[0][idx]\n",
        "      true_label = y_test[idx]\n",
        "\n",
        "      upper_preds.append(upper_pred)\n",
        "      lower_preds.append(lower_pred)\n",
        "\n",
        "    upper_mae = mae(y_test, upper_preds)\n",
        "    lower_mae = mae(y_test, lower_preds)\n",
        "    full_mae = upper_mae + lower_mae\n",
        "    test_maes.append(full_mae)\n",
        "\n",
        "  print(\"Test MAE: {:2f}, +/-{:2f}\".format(np.mean(test_maes), np.std(test_maes)))"
      ],
      "metadata": {
        "id": "G-RXNox0q5oZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_test_mae_mc(iterations, x_train, y_train, x_test, y_test):\n",
        "  test_maes = []\n",
        "  quantiles = [0.05, 0.95]\n",
        "  for n in range(iterations):\n",
        "    model = build_mqnn(quantiles, x_train, [128, 128], True)\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
        "    montecarlo_predictions = []\n",
        "    for i in tqdm.tqdm(range(500)):\n",
        "      prediction = model.predict(x_test, batch_size=1000, verbose=0)\n",
        "      prediction = np.asarray(prediction)\n",
        "      prediction = np.reshape(prediction, prediction.shape[0:2])\n",
        "      montecarlo_predictions.append(prediction)\n",
        "\n",
        "    upper_preds = []\n",
        "    lower_preds = []\n",
        "    # predictions\n",
        "    for idx in tqdm.tqdm(range(len(x_test))):\n",
        "      pred_mean = np.mean(montecarlo_predictions, axis=0)\n",
        "      upper_pred = pred_mean[1][idx]\n",
        "      lower_pred = pred_mean[0][idx]\n",
        "      true_label = y_test[idx]\n",
        "\n",
        "      upper_preds.append(upper_pred)\n",
        "      lower_preds.append(lower_pred)\n",
        "\n",
        "    upper_mae = mae(y_test, upper_preds)\n",
        "    lower_mae = mae(y_test, lower_preds)\n",
        "    full_mae = upper_mae + lower_mae\n",
        "    test_maes.append(full_mae)\n",
        "  print(\"Test MAE: {:2f}, +/-{:2f}\".format(np.mean(test_maes), np.std(test_maes)))"
      ],
      "metadata": {
        "id": "u7PcyL1Nq6vQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_test_mae_cqr(iterations, x_train, y_train, x_test, y_test):\n",
        "  test_maes = []\n",
        "  quantiles = [0.05, 0.95]\n",
        "  uncal_cov = []\n",
        "  cal_cov = []\n",
        "  for n in range(iterations):\n",
        "    model = build_mqnn(quantiles, x_train, [128, 128], False)\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
        "    prediction = model.predict(x_test, batch_size=1000, verbose=0)\n",
        "\n",
        "    # calibration\n",
        "    n = 10\n",
        "    alpha = 0.1\n",
        "\n",
        "    idx = np.array([1] * n + [0] * (len(y_test) - n)) > 0\n",
        "    np.random.shuffle(idx)\n",
        "    cal_labels, val_labels = y_test[idx], y_test[~idx]\n",
        "    cal_upper, val_upper = prediction[1][idx], prediction[1][~idx]\n",
        "    cal_lower, val_lower = prediction[0][idx], prediction[0][~idx]\n",
        "\n",
        "    cal_scores = np.maximum(cal_labels-cal_upper, cal_lower-cal_labels)\n",
        "    qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, method='higher')\n",
        "\n",
        "    prediction_sets = [val_lower - qhat, val_upper + qhat]\n",
        "\n",
        "    # coverage\n",
        "    prediction_sets_uncalibrated = [val_lower, val_upper]\n",
        "    empirical_coverage_uncalibrated = ((val_labels >= prediction_sets_uncalibrated[0]) & (val_labels <= prediction_sets_uncalibrated[1])).mean()\n",
        "    uncal_cov.append(empirical_coverage_uncalibrated)\n",
        "    empirical_coverage = ((val_labels >= prediction_sets[0]) & (val_labels <= prediction_sets[1])).mean()\n",
        "    cal_cov.append(empirical_coverage)\n",
        "\n",
        "    upper_preds = []\n",
        "    lower_preds = []\n",
        "    # predictions\n",
        "    for idx in tqdm.tqdm(range(len(val_lower))):\n",
        "      #upper_pred = prediction_sets[1][idx]\n",
        "      #lower_pred = prediction_sets[0][idx]\n",
        "      upper_pred = val_upper[idx]\n",
        "      lower_pred = val_lower[idx]\n",
        "      true_label = val_labels[idx]\n",
        "\n",
        "      upper_preds.append(upper_pred)\n",
        "      lower_preds.append(lower_pred)\n",
        "\n",
        "    upper_mae = mae(val_labels, upper_preds)\n",
        "    lower_mae = mae(val_labels, lower_preds)\n",
        "    full_mae = upper_mae + lower_mae\n",
        "    test_maes.append(full_mae)\n",
        "\n",
        "  print(\"Test MAE: {:2f}, +/-{:2f}\".format(np.mean(test_maes), np.std(test_maes)))\n",
        "  print(\"The empirical coverage before calibration is: {:2f}, +/-{:2f}\".format(np.mean(uncal_cov), np.std(uncal_cov)))\n",
        "  print(\"The empirical coverage after calibration is: {:2f}, +/-{:2f}\".format(np.mean(cal_cov), np.std(cal_cov)))"
      ],
      "metadata": {
        "id": "XehYdO-3q7oO"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_test_mae_mccqr(iterations, x_train, y_train, x_test, y_test):\n",
        "  test_maes = []\n",
        "  quantiles = [0.05, 0.95]\n",
        "  uncal_cov = []\n",
        "  cal_cov = []\n",
        "  for n in range(iterations):\n",
        "    model = build_mqnn(quantiles, x_train, [128, 128], True)\n",
        "    history = model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "    montecarlo_predictions = dynamic_mc_predict_reg(x_test, model, 10, 5e-4, 1000)\n",
        "\n",
        "    # calibration\n",
        "    n = 10\n",
        "    alpha = 0.1\n",
        "\n",
        "    idx = np.array([1] * n + [0] * (len(y_test) - n)) > 0\n",
        "    np.random.shuffle(idx)\n",
        "    cal_labels, val_labels = y_test[idx], y_test[~idx]\n",
        "    cal_upper, val_upper = montecarlo_predictions[:,1][idx], montecarlo_predictions[:,1][~idx]\n",
        "    cal_lower, val_lower = montecarlo_predictions[:,0][idx], montecarlo_predictions[:,0][~idx]\n",
        "\n",
        "    cal_scores = np.maximum(cal_labels-cal_upper, cal_lower-cal_labels)\n",
        "    qhat = np.quantile(cal_scores, np.ceil((n+1)*(1-alpha))/n, method='higher')\n",
        "\n",
        "    prediction_sets = [val_lower - qhat, val_upper + qhat]\n",
        "\n",
        "    # coverage\n",
        "    prediction_sets_uncalibrated = [val_lower, val_upper]\n",
        "    empirical_coverage_uncalibrated = ((val_labels >= prediction_sets_uncalibrated[0]) & (val_labels <= prediction_sets_uncalibrated[1])).mean()\n",
        "    uncal_cov.append(empirical_coverage_uncalibrated)\n",
        "    empirical_coverage = ((val_labels >= prediction_sets[0]) & (val_labels <= prediction_sets[1])).mean()\n",
        "    cal_cov.append(empirical_coverage)\n",
        "\n",
        "    upper_preds = []\n",
        "    lower_preds = []\n",
        "    # predictions\n",
        "    for idx in tqdm.tqdm(range(len(val_lower))):\n",
        "      #upper_pred = prediction_sets[1][idx]\n",
        "      #lower_pred = prediction_sets[0][idx]\n",
        "      upper_pred = val_upper[idx]\n",
        "      lower_pred = val_lower[idx]\n",
        "      true_label = val_labels[idx]\n",
        "\n",
        "      upper_preds.append(upper_pred)\n",
        "      lower_preds.append(lower_pred)\n",
        "\n",
        "    upper_mae = mae(val_labels, upper_preds)\n",
        "    lower_mae = mae(val_labels, lower_preds)\n",
        "    full_mae = upper_mae + lower_mae\n",
        "    test_maes.append(full_mae)\n",
        "\n",
        "  print(\"Test MAE: {:2f}, +/-{:2f}\".format(np.mean(test_maes), np.std(test_maes)))\n",
        "  print(\"The empirical coverage before calibration is: {:2f}, +/-{:2f}\".format(np.mean(uncal_cov), np.std(uncal_cov)))\n",
        "  print(\"The empirical coverage after calibration is: {:2f}, +/-{:2f}\".format(np.mean(cal_cov), np.std(cal_cov)))"
      ],
      "metadata": {
        "id": "9yx0Nw9iq9F8"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tests"
      ],
      "metadata": {
        "id": "ARE3RkJtqxOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n",
        "regression_test_mae_regular(1, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "6IkMjIEMqupM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n",
        "regression_test_mae_mc(1, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "rWOuJ7Bbr9z2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n",
        "regression_test_mae_cqr(1, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "VoFWRi9lr-c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train, x_test, y_test, idx_train, idx_cal, input_shape = load_housing_prices()\n",
        "regression_test_mae_mccqr(1, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "id": "vzwZydYIr_ED"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}